{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [Background](#background)<br><br>\n",
    "2. [Hypothesis testing with one sample](#onesamp)<br>\n",
    "    2a. [if population sigma is unknown -> t distribution](#t_1s)<br>\n",
    "    2b. [if population sigma is known -> normal distribution](#norm_1s)<br>\n",
    "    2c. [for a poplation proportion -> binomial as normal](#bi_1s)<br><br>\n",
    "3. [Hypothesis testing with two independent samples](#twosamp_ind)<br>\n",
    "    3a. [Welch](#welch)<br>\n",
    "    3b. [Cohen's d](#cohen_d)<br>\n",
    "    3c. [Two independent proportions](#ind_pro)<br><br>\n",
    "4. [Hypothesis testing with two dependent samples](#twosamp_dep)<br><br>\n",
    "5. [Chi squared test](#chi_sq)<br>\n",
    "    5a. [Goodness-of-fit](#chi_fit)<br>\n",
    "    5b. [Independence](#chi_ind)<br>\n",
    "    5c. [Homogeneity](#chi_homo)<br>\n",
    "    5d. [Single variance](#chi_var)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background<a class=\"anchor\" id=\"background\"></a>\n",
    "\n",
    "A **hypothesis test** is a statistical inference that makes a decision about the validity of an assertion which has been translated into a statistic. It considers a **null hypothesis** $H_0$ against an **alternative hypothesis** $H_1$ or $H_a$. The null hypothesis represents some default position that the results of the test will either rejected or failed to reject in favor of the alternative hypothesis which is the opposite of the null.\n",
    "> $H_0$ null hypothesis<br>\n",
    "$H_1$ alternative hypothesis \n",
    "\n",
    "Before data collection, a **signifiance level**, $\\alpha$, is chosen. It represents the probability that the rest will incorrectly reject the null hypothesis (that is reject it even though it is true). After data collection, the signifiance level is compared against the **p-value** which is the probability of observing a test statistic at least as extreme as the one actually obsevered given that null hypothesis is true. \n",
    ">If p-value < $\\alpha$ then the null hypothesis is rejected at significance level $\\alpha$.\n",
    "\n",
    "The **signifiance** of a test is the probability of making a **type 1 error** or **false positive**. Also of interest is the probability failing to reject the null hypothesis when it is false $\\beta$. That is a **type 2 error** or **false negative**. This is more commonly expression as the probability of *not* making a type 2 error or the **power** of the test $1 - \\beta$.<br>\n",
    ">$\\alpha$ = P(type 1)<br>\n",
    "$\\beta$ = P(type 2)<br><br>\n",
    "signifiance = $\\alpha$<br>\n",
    "power = $1 - \\beta$\n",
    "\n",
    "Tests can be left-tailed, right-tailed or two-tailed depending on the hypothesis:<br>\n",
    ">Left-tailed: p-value is in the left tail of the distribution\n",
    "$H_0$: $\\mu >= x$ and $H_1$: $\\mu < x$<br>\n",
    "Right-tailed: p-value is in the right tail of the distribution\n",
    "$H_0$: $\\mu <= x$ and $H_1$: $\\mu > x$<br>\n",
    "Two-tailed: p-value split evenly between both tails of the distribution\n",
    "$H_0$: $\\mu = x$ and $H_1$: $\\mu <> x$<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing with one sample<a class=\"anchor\" id=\"onesamp\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single population mean -  unknown population standard deviation <a class=\"anchor\" id=\"t_1s\"></a> \n",
    "\n",
    "When the population standard deviation is unknown (as is usually the case) a Students t-test should be used. Note: the sample mean distribution must be approximately normal. That is, if n is small the population distribution should be normal where if n is large this is not required.\n",
    "\n",
    "The p-value is calculated for the hypothesis is calculated using a t distribution with n - 1 degrees of freedom. The sample standard deviation **s** to approximate population standard deviation. Remember to use n - 1 in the denominator when calculating **s**.\n",
    "\n",
    "This can be done using Scipy stats.ttest_1samp. The scipy method returns a tuple (test_statistic, p-value). The test statistic is the value on a standart t-distribution of speficied df and the p-value is for a two tailed t-test. A one tailed test is found by dividing simply dividing the p-value by two (that is, for the tail that might be interesting (ie. if x_bar = 1.1 and h0 was x > 1 it's not getting rejected, but if h0 was x < 1 dividing by two gives you the correct p-value))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value is 0.0359\n",
      "The p-value is 0.0359 (using scipy method, dividing by two for 1 tailed test)\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 9.20\n",
    "# right tailed t-test\n",
    "data = [1.11, 1.07, 1.11, 1.07, 1.12, 1.08, 0.98, 0.98, 1.02, 0.95, 0.95]\n",
    "h = 1.00 # null hypothesis: mean <= 1\n",
    "\n",
    "# Using distribution explicitly (long way for explainatory purposes)\n",
    "n = len(data)\n",
    "x_bar = np.mean(data)\n",
    "s = np.std(data, ddof=1) # sample std -> ddof = 1\n",
    "pval = stats.t.sf(x_bar, n - 1, h, s / np.sqrt(n)) \n",
    "print('The p-value is {0:.4f}'.format(pval))\n",
    "\n",
    "# The one-tail that's interesting is half the two-tailed\n",
    "# * i.e. hypothesis mean <= 1 will never be rejected by a mean <= 1\n",
    "pval = stats.ttest_1samp(data, h)[1] / 2\n",
    "print('The p-value is {0:.4f} (using scipy method, dividing by two for 1 tailed test)'.format(pval))\n",
    "\n",
    "# If you really want the one tail for the side that will never reject the null  \n",
    "#print(1 - (stats.ttest_1samp(data, h)[1]) / 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single population mean - known population standard deviation<a class=\"anchor\" id=\"norm_1s\"></a> \n",
    "\n",
    "When the population standard deviation is known (rarely the case) the p-value should be calculated using a normal distribution, sometimes called a z-test.\n",
    "\n",
    "$$\\bar{X} \\sim N(\\mu_X, \\frac{\\sigma_X}{{\\sqrt{n}}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the sample mean = 17\n",
      "  If the null hypothesis was a population mean <= 15, the p-value = 1.0000\n",
      "  If the null hypothesis was a population mean >= 15, the p-value = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 9.9\n",
    "#  null hypothesis mu >= h -> use left tail test\n",
    "#  right tail test included for playing with inputs \n",
    "h = 15  \n",
    "n = 10\n",
    "x_bar = 17   # Sample mean\n",
    "sigma = 0.5  # Known population standard deviation\n",
    "\n",
    "pval_righttail = stats.norm.cdf(x_bar, h, (sigma / np.sqrt(n))) # Left tail test\n",
    "#pval_lefttail = 1 - stats.norm.cdf(x_bar, h, (sigma / np.sqrt(n))) # Right tail test\n",
    "pval_lefttail = stats.norm.sf(x_bar, h, (sigma / np.sqrt(n))) # More accurate right tail test\n",
    "\n",
    "print('For the sample mean = {0}'.format(x_bar))\n",
    "print('  If the null hypothesis was a population mean <= {0}, the p-value = {1:.4f}'\\\n",
    "         .format(h, pval_righttail))\n",
    "print('  If the null hypothesis was a population mean >= {0}, the p-value = {1:.4f}'\\\n",
    "         .format(h, pval_lefttail))\n",
    "\n",
    "# The z-test is not implemented in scipy. \n",
    "# The statsmodels module has an implementation, but it uses the sample standard deviation which\n",
    "# defeats using it when the population standard deviation is known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  For the null hypothesis was a population mean <= 16.43, the p-value = 0.0187\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 9.14 \n",
    "#  null hypothesis mu <= h -> use right tail test\n",
    "#  see previous example 9.9 for mu >= h\n",
    "h = 16.43  \n",
    "n = 15\n",
    "x_bar = 16   # Sample mean\n",
    "sigma = 0.8  # Known population standard deviation\n",
    "\n",
    "pval_righttail = stats.norm.cdf(x_bar, h, (sigma / np.sqrt(n))) # Left tail test\n",
    "pval_lefttail = stats.norm.sf(x_bar, h, (sigma / np.sqrt(n))) # More accurate right tail test\n",
    "\n",
    "print('  For the null hypothesis was a population mean <= {0}, the p-value = {1:.4f}'\\\n",
    "         .format(h, pval_righttail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population proportion<a class=\"anchor\" id=\"bi_1s\"></a> \n",
    "\n",
    "Approximate as a normal distribution for a binomial divided by n. \n",
    "$$\\large{P}' \\sim N(p, \\sqrt{\\normalsize\\frac{p q}{n}})$$\n",
    "\n",
    "Note: Requires np > 5 and nq > 5 for an accurate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5485062355001469\n",
      "0.5485062355001469\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 9.17\n",
    "# two-tailed\n",
    "\n",
    "h = 0.50  # hypothesis proportion\n",
    "\n",
    "n = 100   # number of samples\n",
    "p = 0.53  # proportion observed\n",
    "\n",
    "sigma = np.sqrt(h * (1 - h) / n)  # for proportion from binomial\n",
    "\n",
    "# explainatory path to p-value \n",
    "if h < p:\n",
    "    right_tail = stats.norm.sf(p, h, sigma)\n",
    "    left_tail = stats.norm.cdf(h + (h - p), h, sigma)\n",
    "else:\n",
    "    right_tail = stats.norm.sf(h + (h - p), h, sigma)\n",
    "    left_tail = stats.norm.cdf(p, h, sigma)\n",
    "pval = right_tail + left_tail\n",
    "print(pval)\n",
    "\n",
    "# one line to p-value       \n",
    "pval = 2 * stats.norm.sf(h + np.abs(h - p), h, sigma)\n",
    "    \n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing with two independent samples<a class=\"anchor\" id=\"twosamp_ind\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Welch<a class=\"anchor\" id=\"welch\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.84659125336577\n",
      "0.005401921297382211\n"
     ]
    }
   ],
   "source": [
    "# Two populations\n",
    "\n",
    "n_x = 9      # number of x\n",
    "x_bar = 2    # average for x\n",
    "s_x = 0.866  # sample sigma for x\n",
    "\n",
    "n_y = 16     # number of y\n",
    "y_bar = 3.2  # average for y\n",
    "s_y = 1      # sample sigma for y\n",
    "\n",
    "# DOF - Welch Test\n",
    "dof = ((s_x ** 2 / n_x + s_y ** 2 / n_y) ** 2 / \n",
    "      (1 / (n_x - 1) * (s_x ** 2 / n_x) ** 2 + \n",
    "       1 / (n_y - 1) * (s_y ** 2 / n_y) ** 2))\n",
    "print(dof)\n",
    "\n",
    "# Standard Error\n",
    "std_err = np.sqrt((s_x ** 2 / n_x) + (s_y ** 2 / n_y))\n",
    "\n",
    "pval = (stats.t.sf(np.abs(x_bar - y_bar), dof, 0, std_err) +\n",
    "        stats.t.cdf(-1 * np.abs(x_bar - y_bar), dof, 0, std_err))\n",
    "\n",
    "print(pval)\n",
    "\n",
    "# If the data is available scipy.stats.ttest_ind(a, b, equal_var=False) can be used\n",
    "# Note: if equal_var: perform a student's independent 2 sample test \n",
    "#       (assumes equal population sizes and variances) \n",
    "#       if not equal_var: perform Welchâ€™s t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### right tailed dist + Cohen's d<a class=\"anchor\" id=\"cohen_d\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1928185434187067\n",
      "0.3841106397986879\n"
     ]
    }
   ],
   "source": [
    "# h0 mean of X less than mean of Y # right tailed distribution   \n",
    "\n",
    "n_x = 11\n",
    "x_bar = 4\n",
    "s_x = 1.5\n",
    "\n",
    "n_y = 9\n",
    "y_bar = 3.5\n",
    "s_y = 1\n",
    "\n",
    "# DOF - Welch Test\n",
    "dof = ((s_x ** 2 / n_x + s_y ** 2 / n_y) ** 2 / \n",
    "      (1 / (n_x - 1) * (s_x ** 2 / n_x) ** 2 + \n",
    "       1 / (n_y - 1) * (s_y ** 2 / n_y) ** 2))\n",
    "\n",
    "std_err = np.sqrt(s_x ** 2 / n_x + s_y ** 2 / n_y)\n",
    "\n",
    "pval = (stats.t.sf(x_bar - y_bar, dof, 0, std_err))\n",
    "\n",
    "print(pval)\n",
    "\n",
    "# cohen's d\n",
    "\n",
    "s_pooled = np.sqrt((((n_x - 1) * s_x ** 2) +\n",
    "                    ((n_y - 1) * s_y ** 2)) / \n",
    "                   (n_x + n_y - 2))\n",
    "\n",
    "cohen_d = (x_bar - y_bar) / s_pooled\n",
    "\n",
    "print(cohen_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Independent Population Proportions<a class=\"anchor\" id=\"ind_pro\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1403686607716731\n"
     ]
    }
   ],
   "source": [
    "x_a = 20\n",
    "n_a = 200\n",
    "x_b = 12\n",
    "n_b = 200\n",
    "\n",
    "p_a = (x_a / n_a)\n",
    "p_b = (x_b / n_b)\n",
    "p_c = (x_a + x_b) / (n_a + n_b)  # pooled proportion\n",
    "\n",
    "sigma = np.sqrt(p_c * (1 - p_c) * (1 / n_a + 1 / n_b))\n",
    "\n",
    "if p_a < p_b:\n",
    "    p_a, p_b = p_b, p_a\n",
    "p_val = (stats.norm.sf((p_a - p_b), 0, sigma) +\n",
    "         stats.norm.cdf(0 - (p_a - p_b), 0, sigma))\n",
    "\n",
    "print(p_val)\n",
    "\n",
    "# not sure you can one line this with scipy, but probably with stats models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing with two dependent samples<a class=\"anchor\" id=\"twosamp_dep\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2 -4.1 -1.6 -1.8 -3.2 -2.  -2.9 -9.6]\n",
      "-3.1250000000000004 2.911430674329817\n",
      "0.009477987786306367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.009477987786306376"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_before = [6.6, 6.5, 9.0, 10.3, 11.3, 8.1, 6.3, 11.6]\n",
    "data_after =  [6.8, 2.4, 7.4,  8.5,  8.1, 6.1, 3.4,  2.0]\n",
    "\n",
    "n = len(data_before)\n",
    "\n",
    "before_array = np.array(data_before)\n",
    "after_array = np.array(data_after)\n",
    "diff_array = after_array - before_array\n",
    "\n",
    "print(diff_array)\n",
    "\n",
    "x_bar_diff = diff_array.mean()\n",
    "s_diff = diff_array.std(ddof=1)\n",
    "print(x_bar_diff, s_diff)\n",
    "\n",
    "p_val = stats.t.cdf(x_bar_diff, n - 1, 0, s_diff / np.sqrt(n))\n",
    "\n",
    "print(p_val)\n",
    "\n",
    "# One line scipy stats method\n",
    "#   divide p-val by two for one tailed test\n",
    "stats.ttest_rel(data_after, data_before)[1] / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90 11 -8 -8]\n",
      "0.2149441957535246\n",
      "0.2149441957535246\n",
      "0.2149441957535246\n"
     ]
    }
   ],
   "source": [
    "# right tailed\n",
    "\n",
    "data_before = [205, 241, 338, 368]\n",
    "data_after  = [295, 252, 330, 360]\n",
    "\n",
    "n = len(data_before)\n",
    "\n",
    "before_array = np.array(data_before)\n",
    "after_array = np.array(data_after)\n",
    "diff_array = after_array - before_array\n",
    "\n",
    "print(diff_array)\n",
    "\n",
    "x_bar_diff = diff_array.mean()\n",
    "s_diff = diff_array.std(ddof=1)\n",
    "\n",
    "p_val = stats.t.sf(x_bar_diff, n - 1, 0, s_diff / np.sqrt(n))\n",
    "\n",
    "print(p_val)\n",
    "\n",
    "print(stats.ttest_rel(data_after, data_before)[1] / 2) # divide by two for one tailed test \n",
    "print(stats.ttest_rel(data_before, data_after)[1] / 2) # ttest_rel tests the hypothesis that might be rejected\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared test<a class=\"anchor\" id=\"chi_sq\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goodness-of-fit<a class=\"anchor\" id=\"chi_fit\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5578254003710748\n",
      "Power_divergenceResult(statistic=3.0, pvalue=0.5578254003710748)\n"
     ]
    }
   ],
   "source": [
    "exp_dist = [12, 12, 12, 12, 12]  # Expected distribution\n",
    "obs_dist = [15, 12,  9,  9, 15]  # Oberved distribution\n",
    "\n",
    "dof = len(exp_dist) - 1\n",
    "\n",
    "exp = np.array(exp_dist)\n",
    "obs = np.array(obs_dist)\n",
    "\n",
    "chi_stat = sum(((obs - exp) ** 2) / exp)\n",
    "\n",
    "p_val = stats.chi2.sf(chi_stat, dof)\n",
    "\n",
    "print(p_val)\n",
    "\n",
    "\n",
    "# one line scipy stats method\n",
    "#   dof defaults to k - 1, method accepts ddof argument which will set dof to k - 1 - ddof\n",
    "print(stats.chisquare(obs_dist, exp_dist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independence<a class=\"anchor\" id=\"chi_ind\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90.57210965 115.19070322  49.23718713]\n",
      " [103.00357569 131.0011919   55.99523242]\n",
      " [104.42431466 132.80810489  56.76758045]]\n",
      "12.990918513170868\n",
      "0.011320253054188366\n",
      "\n",
      "(12.990918513170868, 0.011320253054188366, 4, array([[ 90.57210965, 115.19070322,  49.23718713],\n",
      "       [103.00357569, 131.0011919 ,  55.99523242],\n",
      "       [104.42431466, 132.80810489,  56.76758045]]))\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[111, 96, 48],\n",
    "                 [96, 133, 61],\n",
    "                 [91, 150, 53]])\n",
    "\n",
    "n_terms = data.sum()\n",
    "n_rows = len(data[:, 0])\n",
    "n_cols = len(data[0, :])\n",
    "dof = (n_rows - 1) * (n_cols - 1)\n",
    "\n",
    "# Note - there's probably a better way to do this\n",
    "expected = np.array([[(data[:, j].sum() * data[i, :].sum()) / n_terms \n",
    "                      for j in range(n_cols)] for i in range(n_rows)])\n",
    "\n",
    "chi_stat = (((data - expected) ** 2) / expected).sum()\n",
    "\n",
    "p_val = stats.chi2.sf(chi_stat, dof)\n",
    "\n",
    "print(expected)\n",
    "print(chi_stat)\n",
    "print(p_val)\n",
    "print()\n",
    "\n",
    "# scipy stats method\n",
    "print(stats.chi2_contingency(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homogeneity<a class=\"anchor\" id=\"chi_homo\"></a> \n",
    "\n",
    "This is the test for independence used to determine the probability that two populations have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74.09090909 77.27272727 62.27272727 36.36363636]\n",
      " [88.90909091 92.72727273 74.72727273 43.63636364]]\n",
      "10.128696811826693\n",
      "0.017503254828611012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[72, 84, 49, 45],\n",
    "                 [91, 86, 88, 35]])\n",
    "\n",
    "n_terms = data.sum()\n",
    "n_rows = 2  # Should always be two here\n",
    "n_cols = len(data[0, :])\n",
    "dof = n_cols - 1\n",
    "\n",
    "# Note - there's probably a better way to do this\n",
    "expected = np.array([[(data[:,i].sum() * data[j,:].sum()) / n_terms \n",
    "                      for i in range(n_cols)] for j in range(n_rows)])\n",
    "\n",
    "chi_stat = (((data - expected) ** 2) / expected).sum()\n",
    "\n",
    "p_val = stats.chi2.sf(chi_stat, dof)\n",
    "\n",
    "print(expected)\n",
    "print(chi_stat)\n",
    "print(p_val)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test of a single variance<a class=\"anchor\" id=\"chi_var\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.671296296296296\n",
      "4.213272184766762e-05\n"
     ]
    }
   ],
   "source": [
    "n = 25\n",
    "s = 3.5\n",
    "h = 7.2\n",
    "\n",
    "dof = n - 1\n",
    "\n",
    "chi_stat = ((n - 1) * s ** 2) / h ** 2\n",
    "\n",
    "print(chi_stat)\n",
    "\n",
    "p_val = stats.chi2.cdf(chi_stat, dof)  # left tailed\n",
    "\n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.57889660493827\n",
      "6.1840735576337476e-09\n"
     ]
    }
   ],
   "source": [
    "# increasing n increase test statistic, but decreases p-val for both left and right handed tests,\n",
    "# guessing this is related to the change in distribution with dof?\n",
    "\n",
    "n = 50\n",
    "s = 3.5\n",
    "h = 7.2\n",
    "\n",
    "dof = n - 1\n",
    "\n",
    "chi_stat = ((n - 1) * s ** 2) / h ** 2\n",
    "\n",
    "print(chi_stat)\n",
    "\n",
    "p_val = stats.chi2.cdf(chi_stat, dof)  # left tailed\n",
    "\n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.56408163265307\n",
      "1.623621440614767e-11\n"
     ]
    }
   ],
   "source": [
    "n = 25\n",
    "s = 7.2\n",
    "h = 3.5\n",
    "\n",
    "dof = n - 1\n",
    "\n",
    "chi_stat = ((n - 1) * s ** 2) / h ** 2\n",
    "\n",
    "print(chi_stat)\n",
    "\n",
    "p_val = stats.chi2.sf(chi_stat, dof)  # right tailed\n",
    "\n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207.36\n",
      "2.2435449579324275e-21\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "s = 7.2\n",
    "h = 3.5\n",
    "\n",
    "dof = n - 1\n",
    "\n",
    "chi_stat = ((n - 1) * s ** 2) / h ** 2\n",
    "\n",
    "print(chi_stat)\n",
    "\n",
    "p_val = stats.chi2.sf(chi_stat, dof)  # right tailed\n",
    "\n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for correlation coefficient significance\n",
    "Tests null hypothesis that the population correlation coefficient is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = 0.6631, r^2 = 0.4397, p_val = 0.0262\n"
     ]
    }
   ],
   "source": [
    "x = [ 65,  67,  71,  71,  66,  75,  67,  70,  71,  69,  69]\n",
    "y = [175, 133, 185, 163, 126, 198, 153, 163, 159, 151, 159]\n",
    "\n",
    "r, p_val = stats.pearsonr(x, y)\n",
    "print('r = {0:.4f}, r^2 = {1:.4f}, p_val = {2:.4f}'.format(r, r ** 2, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources<a class=\"anchor\" id=\"sources\"></a>\n",
    "\n",
    "Illowsky, Barbara; Dean, Susan. Introductory Statistics. OpenStax College. Kindle Edition\n",
    "https://openstax.org/details/introductory-statistics\n",
    "\n",
    "SciPy 1.0.0 Release Notes: https://docs.scipy.org/doc/scipy/reference/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
