{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/Software/anaconda2/envs/ds36_env/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [Background](#background)<br><br>\n",
    "2. [Hypothesis testing with one sample](#onesamp)<br>\n",
    "    2a. [if population sigma is unknown -> t distribution](#t_1s)<br>\n",
    "    2b. [if population sigma is known -> normal distribution](#norm_1s)<br>\n",
    "    2c. [for a poplation proportion -> binomial as normal](#bi_1s)<br><br>\n",
    "3. [Hypothesis testing with two independent samples](#twosamp_ind)<br>\n",
    "    3a. [Two independent population means](#twosamp_ind_means)<br>\n",
    "    3b. [Cohen's d and effect size](#cohen_d)<br>\n",
    "    3c. [Two independent population proportions](#ind_pro)<br><br>\n",
    "4. [Hypothesis testing with two dependent samples](#twosamp_dep)<br><br>\n",
    "5. [Chi squared test](#chi_sq)<br>\n",
    "    5a. [Goodness-of-fit](#chi_fit)<br>\n",
    "    5b. [Independence](#chi_ind)<br>\n",
    "    5c. [Homogeneity](#chi_homo)<br>\n",
    "    5d. [Single variance](#chi_var)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background<a class=\"anchor\" id=\"background\"></a>\n",
    "\n",
    "A **hypothesis test** is a statistical inference that makes a decision about the validity of an assertion which has been translated into a statistic. It considers a **null hypothesis** $H_0$ against an **alternative hypothesis** $H_1$ or $H_a$. The null hypothesis represents some default position that the results of the test will either rejected or failed to reject in favor of the alternative hypothesis which is the opposite of the null.\n",
    "> $H_0$ null hypothesis<br>\n",
    "$H_1$ alternative hypothesis \n",
    "\n",
    "Before data collection, a **signifiance level**, $\\alpha$, is chosen. It represents the probability that the rest will incorrectly reject the null hypothesis (that is reject it even though it is true). After data collection, the signifiance level is compared against the **p-value** which is the probability of observing a test statistic at least as extreme as the one actually obsevered given that null hypothesis is true. \n",
    ">If p-value < $\\alpha$ then the null hypothesis is rejected at significance level $\\alpha$. Otherwise it is \"not rejected\" (this does not mean it is accepted as true)<br><br>\n",
    "Note: p-values are prone to misuse and a topic of debate. Here are a few quick points, further reading is recommended:\n",
    "1. $P(D|H_0) <> P(H_0|D)$. The former is what the p-value tells you. The latter is what you want to know, \n",
    "2. The choice of $\\alpha$ sets up a false dichotomy. A p-value = 0.051 vs. = 0.049 is probabilistically very similar, but give opposite conclusions at $\\alpha$ = 0.05.\n",
    "3. When comparing two groups the \"nil hypothesis,\" $\\bar{X_1}-\\bar{X_2} = 0$, is virtiually never true. There is always a difference however slight, so a large enough sample size will always be statistically significant.  \n",
    "4. Temptation to introduce bias through \"data peeking\". That is, running more exmeriments after the planned number gives a p-value is just over $\\alpha$ or terminating experiments early if the p-value is alright significant.\n",
    "5. With many studies being preformed, some will appear significany by chance. In the case of $\\alpha$ = 0.05, 1 in 20 experiments would be false positives. This situation is made worse by a lack of reporting negative results (the \"file drawer problem\").\n",
    "\n",
    "The **signifiance** of a test is the probability of making a **type 1 error** or **false positive**. Also of interest is the probability failing to reject the null hypothesis when it is false $\\beta$. That is a **type 2 error** or **false negative**. This is more commonly expression as the probability of *not* making a type 2 error or the **power** of the test $1 - \\beta$.<br>\n",
    ">$\\alpha$ = P(type 1)<br>\n",
    "$\\beta$ = P(type 2)<br><br>\n",
    "signifiance = $\\alpha$<br>\n",
    "power = $1 - \\beta$\n",
    "\n",
    "Tests can be left-tailed, right-tailed or two-tailed depending on the hypothesis:<br>\n",
    ">Left-tailed: p-value is in the left tail of the distribution\n",
    "$H_0$: $\\mu >= x$ and $H_1$: $\\mu < x$<br>\n",
    "Right-tailed: p-value is in the right tail of the distribution\n",
    "$H_0$: $\\mu <= x$ and $H_1$: $\\mu > x$<br>\n",
    "Two-tailed: p-value split evenly between both tails of the distribution\n",
    "$H_0$: $\\mu = x$ and $H_1$: $\\mu <> x$<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing with one sample<a class=\"anchor\" id=\"onesamp\"></a>\n",
    "\n",
    "Tests comparing a sample statistic to a hypothesized value for the corresponding population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single population mean -  unknown population standard deviation <a class=\"anchor\" id=\"t_1s\"></a> \n",
    "\n",
    "When the population standard deviation is unknown (as is usually the case) a Students t-test should be used \n",
    "\n",
    "**prerequisites:**\n",
    "1. The data must come from a simple random sample. That is, any group of n individuals from the population was equally likely to be chosen for the sample). \n",
    "2. The sample mean distribution must be approximately normal. That is, if n is small the population distribution should be normal where if n is large this is not required.\n",
    "\n",
    "**the t-distribution:**\n",
    "1. Select the t distribution with n - 1 degrees of freedom: $t_{dof} = n-1$\n",
    "2. The hypothesis value is the center of the t distribution: $t_{\\mu} = h_0$\n",
    "3. The sample standard deviation of the mean approximates sigma: $t_{\\sigma} = \\large \\frac{s}{\\sqrt{n}}$<br>\n",
    "4. Alternatively, calculate the t-score: $t_{score} = \\large\\frac{|{\\bar{x}-h_0}|}{\\frac{s}{\\sqrt{n}}}$<br>\n",
    "*Either way remember to use n - 1 in the denominator when calculating s.*\n",
    "\n",
    "**the p-value:**\n",
    "1. Find the probability of observing a value at least as extreme as $\\bar{x}$ using the appropriate tail(s) of the t-distribution. This can be done using the Scipy stats.ttest_1samp method, which returns a tuple (test_statistic, p-value). \n",
    "2. The p-value returned by stats.ttest_1samp is for a two tailed t-test. For a one tailed test divide by two. This gives the tail that might be interesting (x_bar > $h_0$ right-tail, x_bar < $h_0$ left tail). The test statistic is the number of standard deviations $\\bar{x}$ is from ${h_0}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value is 0.0359 (using a scaled t-distribution)\n",
      "The p-value is 0.0359 (using a t-score)\n",
      "The p-value is 0.0359 (using scipy method, dividing by two for 1 tailed test)\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 9.20\n",
    "# right tailed t-test\n",
    "data = [1.11, 1.07, 1.11, 1.07, 1.12, 1.08, 0.98, 0.98, 1.02, 0.95, 0.95]\n",
    "h = 1.00 # null hypothesis: mean <= 1\n",
    "\n",
    "# using scaled t-distribution (long way for explainatory purposes)\n",
    "n = len(data)\n",
    "x_bar = np.mean(data)\n",
    "s = np.std(data, ddof=1) # sample std -> ddof = 1\n",
    "pval = stats.t.sf(x_bar, n - 1, h, s / np.sqrt(n)) \n",
    "print('The p-value is {0:.4f} (using a scaled t-distribution)'.format(pval))\n",
    "\n",
    "# using a t-score (another long way for explainatory purposes)\n",
    "t_score = np.abs(x_bar - h) / (s / np.sqrt(n))\n",
    "pval = stats.t.sf(t_score, n - 1)\n",
    "print('The p-value is {0:.4f} (using a t-score)'.format(pval))\n",
    "\n",
    "# using scipy method\n",
    "t_score, pval = stats.ttest_1samp(data, h)\n",
    "pval = pval / 2\n",
    "print('The p-value is {0:.4f} (using scipy method, dividing by two for 1 tailed test)'.format(pval))\n",
    "# The one-tail that's interesting is half the two-tailed\n",
    "#  i.e. hypothesis mean <= 1 will never be rejected by a mean <= 1\n",
    "#  If you really want the one tail for the side that will never reject the null  \n",
    "#  print(1 - (stats.ttest_1samp(data, h)[1]) / 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single population mean - known population standard deviation<a class=\"anchor\" id=\"norm_1s\"></a> \n",
    "\n",
    "When the population standard deviation is known (rarely the case) the p-value should be calculated similar to the t-test described above, except using a normal distribution and the population standard deviation. This is sometimes called a z-test.\n",
    "\n",
    "$$\\bar{X} \\sim N(\\mu_X, \\frac{\\sigma_X}{{\\sqrt{n}}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the sample mean = 17\n",
      "  If the null hypothesis was a population mean <= 15, the p-value = 1.0000\n",
      "  If the null hypothesis was a population mean >= 15, the p-value = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 9.9\n",
    "#  null hypothesis mu >= h -> use left tail test\n",
    "#  right tail test included for playing with inputs \n",
    "h = 15  \n",
    "n = 10\n",
    "x_bar = 17   # Sample mean\n",
    "sigma = 0.5  # Known population standard deviation\n",
    "\n",
    "pval_righttail = stats.norm.cdf(x_bar, h, (sigma / np.sqrt(n))) # Left tail test\n",
    "#pval_lefttail = 1 - stats.norm.cdf(x_bar, h, (sigma / np.sqrt(n))) # Right tail test\n",
    "pval_lefttail = stats.norm.sf(x_bar, h, (sigma / np.sqrt(n))) # More accurate right tail test\n",
    "\n",
    "print('For the sample mean = {0}'.format(x_bar))\n",
    "print('  If the null hypothesis was a population mean <= {0}, the p-value = {1:.4f}'\\\n",
    "         .format(h, pval_righttail))\n",
    "print('  If the null hypothesis was a population mean >= {0}, the p-value = {1:.4f}'\\\n",
    "         .format(h, pval_lefttail))\n",
    "\n",
    "# The z-test is not implemented in scipy. \n",
    "# The statsmodels module has an implementation, but it uses the sample standard deviation which\n",
    "# defeats using it when the population standard deviation is known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  For the null hypothesis of a population mean <= 16.43, the p-value = 0.0187\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 9.14 \n",
    "#  null hypothesis mu <= h -> use right tail test\n",
    "#  see previous example 9.9 for mu >= h\n",
    "h = 16.43  \n",
    "n = 15\n",
    "x_bar = 16   # Sample mean\n",
    "sigma = 0.8  # Known population standard deviation\n",
    "\n",
    "pval_righttail = stats.norm.cdf(x_bar, h, (sigma / np.sqrt(n))) # Left tail test\n",
    "pval_lefttail = stats.norm.sf(x_bar, h, (sigma / np.sqrt(n))) # More accurate right tail test\n",
    "\n",
    "print('  For the null hypothesis of a population mean <= {0}, the p-value = {1:.4f}'\\\n",
    "         .format(h, pval_righttail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single population proportion<a class=\"anchor\" id=\"bi_1s\"></a> \n",
    "\n",
    "Approximate the proportion as a normal distribution for a binomial divided by n.<br><br>\n",
    "$$\\large{P}' \\sim N(p, \\sqrt{\\normalsize\\frac{p q}{n}})$$\n",
    "\n",
    "Note: Use the p and q from the hypothesis in determining $\\sigma$ of the distribution.<br>\n",
    "Note: Requires np > 5 and nq > 5 for an accurate result.<br>\n",
    "Note: Also requires data to come from a simple random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " For the null hypothesis of a population proportion of 0.5 the p-value = 0.5485\n",
      " For the null hypothesis of a population proportion of 0.5 the p-value = 0.5485\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 9.17\n",
    "# two-tailed test - single population proportion\n",
    "h = 0.50  # hypothesis proportion\n",
    "n = 100   # number of samples\n",
    "p = 0.53  # proportion observed\n",
    "\n",
    "sigma = np.sqrt(h * (1 - h) / n)  # for a proportion\n",
    "\n",
    "# more explainatory code to p-value \n",
    "if h < p:\n",
    "    right_tail = stats.norm.sf(p, h, sigma)\n",
    "    left_tail = stats.norm.cdf(h + (h - p), h, sigma)\n",
    "else:\n",
    "    right_tail = stats.norm.sf(h + (h - p), h, sigma)\n",
    "    left_tail = stats.norm.cdf(p, h, sigma)\n",
    "pval = right_tail + left_tail\n",
    "print(' For the null hypothesis of a population proportion of {0} the p-value = {1:.4f}'.format(h, pval))\n",
    "\n",
    "# one line to p-value       \n",
    "pval = 2 * stats.norm.sf(h + np.abs(h - p), h, sigma)\n",
    "print(' For the null hypothesis of a population proportion of {0} the p-value = {1:.4f}'.format(h, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing with two samples<a class=\"anchor\" id=\"twosamp_ind\"></a> \n",
    "\n",
    "Tests comparing a sample statistics across two groups. The test are treated differently depending on whether the groups consist of unrelated individuals (independent samples) or matched pairs (dependent samples). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population means for two independent samples<a class=\"anchor\" id=\"twosamp_ind_means\"></a> \n",
    "\n",
    "**prerequisites:**\n",
    "1. Simple random samples from two independent populations\n",
    "2. The distribution of the sample means should be normal. That is, if sample sizes are small the population distributions must be normal.\n",
    "\n",
    "**the p-value:**\n",
    "1. Generally the null hypothesis is that the sample means are the same: $\\bar{X_1}-\\bar{X_2} = 0$\n",
    "2. Select the t-distribution degrees of freedom depending on whether the population standard deviations are known to be equal.\n",
    "> If the populations have equal standard deviations, then a pooled standard deviation may be used with $dof = n1 + n2 - 2$<br>\n",
    "> If the populations standard deviations may be different, then the **Aspin-Welch** test should be used. The $dof$ equation is somewhat involved to input here, but easily searched up and coded in the example below.\n",
    "3. Calculate the t-score test statistic as the difference in sample means divided by the standard error:<br>\n",
    "$$\\frac{\\bar{X_1}-\\bar{X_2}}{\\sigma}$$<br>\n",
    "$$\\sigma = \\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}$$\n",
    "4. Find the probability of observing a value at least as extreme as $\\bar{x}$. This can be done using the Scipy stats.ttest_ind method, which returns a tuple (test_statistic, p-value). Note method parameter equal_var should be set to False if the populations may have unequal variences or different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of degrees of freedom using the Welch test = 18.85\n",
      "The p-value for the two population means being the same = 0.0054\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 10.1\n",
    "#  Two independent samples, unknown, possibly different, standard deviations\n",
    "#  two-tailed test\n",
    "n_x = 9      # number of x\n",
    "x_bar = 2    # average for x\n",
    "s_x = 0.866  # sample sigma for x\n",
    "\n",
    "n_y = 16     # number of y\n",
    "y_bar = 3.2  # average for y\n",
    "s_y = 1      # sample sigma for y\n",
    "\n",
    "h = 0        # Hypothesis X1_bar - X2_bar = 0\n",
    "\n",
    "# DOF - Welch Test\n",
    "dof = ((s_x ** 2 / n_x + s_y ** 2 / n_y) ** 2 / \n",
    "      (1 / (n_x - 1) * (s_x ** 2 / n_x) ** 2 + \n",
    "       1 / (n_y - 1) * (s_y ** 2 / n_y) ** 2))\n",
    "print('The number of degrees of freedom using the Welch test = {0:.2f}'.format(dof))\n",
    "\n",
    "std_err = np.sqrt((s_x ** 2 / n_x) + (s_y ** 2 / n_y))\n",
    "t_score = (np.abs(x_bar - y_bar)) / std_err\n",
    "pval = stats.t.sf(t_score, dof) * 2   # * 2 for two-tailed test\n",
    "print('The p-value for the two population means being the same = {0:.4f}'.format(pval))\n",
    "\n",
    "# If the data is available scipy.stats.ttest_ind(a, b, equal_var=False) can be used\n",
    "# (see Example 10.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value for the first population mean being greater than the face-to-face population mean = 0.1928\n",
      "The Cohen's d = 0.384\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 10.2 and 10.4\n",
    "# h0: X_bar > Y_bar (right-tailed distribution)  \n",
    "n_x = 11\n",
    "x_bar = 4\n",
    "s_x = 1.5\n",
    "\n",
    "n_y = 9\n",
    "y_bar = 3.5\n",
    "s_y = 1\n",
    "\n",
    "# DOF - Welch Test\n",
    "dof = ((s_x ** 2 / n_x + s_y ** 2 / n_y) ** 2 / \n",
    "      (1 / (n_x - 1) * (s_x ** 2 / n_x) ** 2 + \n",
    "       1 / (n_y - 1) * (s_y ** 2 / n_y) ** 2))\n",
    "\n",
    "std_err = np.sqrt(s_x ** 2 / n_x + s_y ** 2 / n_y)\n",
    "pval = (stats.t.sf(x_bar - y_bar, dof, 0, std_err))\n",
    "# If raw data are available scipy stats.ttest_ind can be used. See example 10.3\n",
    "\n",
    "print('The p-value for the first population mean being greater than the face-to-face '\n",
    "      'population mean = {0:.4f}'.format(pval))\n",
    "\n",
    "# Example 10.4 \n",
    "# cohen's d (see discription below)\n",
    "s_pooled = np.sqrt((((n_x - 1) * s_x ** 2) + ((n_y - 1) * s_y ** 2)) / (n_x + n_y - 2))\n",
    "cohen_d = np.abs(x_bar - y_bar) / s_pooled\n",
    "\n",
    "print(\"The Cohen's d = {0:.3f}\".format(cohen_d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value for the online population mean being less than the face-to-face population mean = 0.0011\n",
      "The Cohen's d = 0.834\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 10.3 and 10.5\n",
    "data_online = np.array(\n",
    "    [67.6, 41.2, 85.3, 55.9, 82.4, 91.2, 73.5, 94.1, 64.7, 64.7,\n",
    "     70.6, 38.2, 61.8, 88.2, 70.6, 58.8, 91.2, 73.5, 82.4, 35.5,\n",
    "     94.1, 88.2, 64.7, 55.9, 88.2, 97.1, 85.3, 61.8, 79.4, 79.4])\n",
    "\n",
    "data_face = np.array(\n",
    "    [77.9, 95.3, 81.2, 74.1, 98.8, 88.2, 85.9, 92.9, 87.1, 88.2,\n",
    "     69.4, 57.6, 69.4, 67.1, 97.6, 85.9, 88.2, 91.8, 78.8, 71.8,\n",
    "     98.8, 61.2, 92.9, 90.6, 97.6, 100,  95.3, 83.5, 92.9, 89.4])\n",
    "\n",
    "t_score, pval = (stats.ttest_ind(data_online, data_face, equal_var=False))\n",
    "# Note: for possibly unequal population variances or sizes, argument equal_var=False\n",
    "\n",
    "# For left tailed test (H0: data_online >= data_face)\n",
    "if np.mean(data_online) < np.mean(data_face):\n",
    "    pval = pval / 2\n",
    "else:\n",
    "    pval = 1 - (pval / 2)\n",
    "    \n",
    "print('The p-value for the online population mean being less than the face-to-face '\n",
    "      'population mean = {0:.4f}'.format(pval))\n",
    "\n",
    "# Cohen's d - example 10.5 (see discription below)\n",
    "n_x = len(data_online)\n",
    "x_bar = np.mean(data_online)\n",
    "s_x = np.std(data_online, ddof=1)\n",
    "n_y = len(data_face)\n",
    "y_bar = np.mean(data_face)\n",
    "s_y = np.std(data_face, ddof=1)\n",
    "\n",
    "s_pooled = np.sqrt((((n_x - 1) * s_x ** 2) + ((n_y - 1) * s_y ** 2)) / (n_x + n_y - 2))\n",
    "cohen_d = np.abs(x_bar - y_bar) / s_pooled\n",
    "\n",
    "print(\"The Cohen's d = {0:.3f}\".format(cohen_d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohen's d and effect size<a class=\"anchor\" id=\"cohen_d\"></a> \n",
    "\n",
    "While p-values can test for statistical signifiance in the difference of two populations, they do not report on the **effect size** or magnitude of this difference.\n",
    "\n",
    "**Cohen's d** is a common measure of effect size equal to the difference of two means divided by their pooled standard deviation. Standards for interpreting a Cohen's d are: 0.2 is small, 0.5 is medium and 0.8 is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples (10.4 and 10.5) in previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### two independent population proportions<a class=\"anchor\" id=\"ind_pro\"></a> \n",
    "\n",
    "**prerequisites:**\n",
    "1. Simple random samples from two independent populations\n",
    "2. Number of success and number of failures >5 for each sample.\n",
    "3. The population sizes > 10 times the sample sizes.\n",
    "\n",
    "**the p-value:**\n",
    "1. Select the null and alternative hypothesis. For two populations A and B. Generally that the proportions are the same.<br> \n",
    "$H_0$: $p_a - p_b = 0$<br>\n",
    "$p_a = \\large\\frac{x_a}{n_a}$<br>\n",
    "$x_a =$ number of individuals meeting the condition in group A<br>\n",
    "$n_a =$ total number of individuals in group A<br>\n",
    "(likewise for group B)<br><br>\n",
    "2. Use a pooled proportion and sample number to calculate the test statistic.<br><br>\n",
    "pooled proportion: $p_c = \\large\\frac{x_a + x_b}{n_a + n_b}$<br><br>\n",
    "test statistic: z-score $= \\large\\frac{p_a - p_b}{p_c (1 - p_c) (\\large\\frac{1}{n_a}+\\frac{1}{n_b}\\normalsize)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value for the proportion = 0.1404\n",
      "The p-value for the proportion = 0.1404 (using statsmodels module)\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 10.8 \n",
    "x_a = 20\n",
    "n_a = 200\n",
    "x_b = 12\n",
    "n_b = 200\n",
    "\n",
    "p_a = (x_a / n_a)\n",
    "p_b = (x_b / n_b)\n",
    "p_c = (x_a + x_b) / (n_a + n_b)  # pooled proportion\n",
    "sigma = np.sqrt(p_c * (1 - p_c) * (1 / n_a + 1 / n_b))\n",
    "z_score = (p_a - p_b) / sigma\n",
    "p_val = (stats.norm.sf(z_score) * 2)\n",
    "print('The p-value for the proportion = {0:.4f}'.format(p_val))\n",
    "\n",
    "# The statsmodels module has a function for this\n",
    "z_score, p_val = sm.stats.proportions_ztest([x_a, x_b], [n_a, n_b])\n",
    "print('The p-value for the proportion = {0:.4f} (using statsmodels module)'.format(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing with two dependent samples<a class=\"anchor\" id=\"twosamp_dep\"></a>\n",
    "\n",
    "**prerequisites:**\n",
    "1. Simple random samples from two populations with matched pairs of samples drawn from the source.\n",
    "2. The distribution of the sample means should be normal. That is, if sample sizes are small the population distributions must be normal.\n",
    "\n",
    "**the p-value:**\n",
    "1. Generally the null hypothesis is that there is no difference between the two groups\n",
    "2. The differences of the matched pairs are used for the hypothesis test essientially making it a test for one sample where that sample is the differences.\n",
    "t-score $=\\large\\frac{\\bar{x}_d}{\\Large(\\frac{s_d}{\\sqrt{n}})}$<br>\n",
    "$\\bar{x}_d$ = the mean difference of the samples<br>\n",
    "${s_d}$ = the standard deviation of the difference of the samples<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value is 0.0095\n",
      "The p-value is 0.0095 (using scipy ttest_rel)\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 10.11\n",
    "# left-tailed, two dependent samples\n",
    "data_before = np.array([6.6, 6.5, 9.0, 10.3, 11.3, 8.1, 6.3, 11.6])\n",
    "data_after  = np.array([6.8, 2.4, 7.4,  8.5,  8.1, 6.1, 3.4,  2.0])\n",
    "\n",
    "# Uncomment to test directionality (matters for single tail tests) \n",
    "# data_before, data_after = data_after, data_before\n",
    "\n",
    "diff = data_after - data_before\n",
    "n = len(diff)  \n",
    "x_bar = diff.mean()\n",
    "s = diff.std(ddof=1)\n",
    "t_score = x_bar / (s / np.sqrt(n))\n",
    "p_val = stats.t.cdf(t_score, n - 1)\n",
    "print('The p-value is {0:.4f}'.format(p_val))\n",
    "\n",
    "# scipy stats method ttest_rel\n",
    "t_score, p_val = stats.ttest_rel(data_after, data_before)\n",
    "# adjust of left-tailed test, h0 = after - before < 0 (after < before)\n",
    "if x_bar < 0:\n",
    "    p_val = p_val / 2   # divide p-val by two for one tailed test\n",
    "else:\n",
    "    p_val = 1 - (p_val / 2)\n",
    "print('The p-value is {0:.4f} (using scipy ttest_rel)'.format(p_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value is 0.2149\n",
      "The p-value is 0.2149 (using scipy ttest_rel)\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 10.12 \n",
    "# right-tailed, two dependent samples\n",
    "data_before = np.array([205, 241, 338, 368])\n",
    "data_after  = np.array([295, 252, 330, 360])\n",
    "\n",
    "diff = data_after - data_before\n",
    "n = len(diff)\n",
    "x_bar = diff.mean()\n",
    "s = diff.std(ddof=1)\n",
    "t_score = x_bar / (s / np.sqrt(n))\n",
    "p_val = stats.t.sf(t_score, n - 1)\n",
    "print('The p-value is {0:.4f}'.format(p_val))\n",
    "\n",
    "t_score, p_val = stats.ttest_rel(data_after, data_before)\n",
    "# adjust of left-tailed test, h0 = after - before > 0 (after > before)\n",
    "if x_bar > 0:\n",
    "    p_val = p_val / 2\n",
    "else:\n",
    "    p_val = 1 - (p_val / 2)\n",
    "print('The p-value is {0:.4f} (using scipy ttest_rel)'.format(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared test<a class=\"anchor\" id=\"chi_sq\"></a> \n",
    "\n",
    "Chi-squared hypothesis testing is used for assessing the probability of independence in categorical data. This extends to goodness-of-fit, homogeneity and single variance tests. It uses the chi-squared distribution which is the sum of k independent, squared standard normal distributions, where k equals the degrees of freedom. The resulting distribution is always greater than 0, nonsymmetric and skewed right.The formula for dof depends on the application.\n",
    "\n",
    "$\\chi^2_{df}$<br> \n",
    "$\\mu = df$<br>\n",
    "$\\sigma = \\sqrt{2 df}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goodness-of-fit<a class=\"anchor\" id=\"chi_fit\"></a> \n",
    "\n",
    "Test to determine how well data fits a particular distribution (commonly a uniform or normal distribution). It involves a bin by bin comparison of expected vs. observed frequencies.\n",
    "\n",
    "$\\large\\sum_k \\large(\\frac{(O\\ -\\ E)^2}{E})$<br>\n",
    "O = observed<br>\n",
    "E = expected<br>\n",
    "k = number of different bins<br>\n",
    "df = k - 1<br>\n",
    "\n",
    "*note: the expected value for each bin must be at least 5*\n",
    "\n",
    "*note: the test is nearly always right tailed (since the chi-squared distribution is always positive, the probability of observing a deviation from observed equal to expected that is at least as large as the deviation seen in the data)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chi^2 p-value = 0.5578\n",
      "The chi^2 p-value = 0.5578 (using stats.chisquare method)\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 11.2\n",
    "#  Goodness-of-fit to uniform distribution\n",
    "obs = np.array([15, 12,  9,  9, 15])  # Oberved distribution\n",
    "\n",
    "# Note, expected value and validity check for uniform distribution\n",
    "#   could be rewriten as array to handle other distributions\n",
    "exp = np.mean(obs) # Expected distribution\n",
    "if exp < 5:\n",
    "    raise UserWarning('''The expected value < 5''')\n",
    "\n",
    "dof = len(obs) - 1\n",
    "chi2_score = sum(((obs - exp) ** 2) / exp)\n",
    "p_val = stats.chi2.sf(chi2_score, dof)\n",
    "print('The chi^2 p-value = {0:.4f}'.format(p_val))\n",
    "\n",
    "# one line scipy stats method\n",
    "#   dof defaults to k - 1, method accepts ddof argument which will set dof to k - 1 - ddof\n",
    "chi2_score, p_val = stats.chisquare(obs, exp)\n",
    "print('The chi^2 p-value = {0:.4f} (using stats.chisquare method)'.format(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independence<a class=\"anchor\" id=\"chi_ind\"></a> \n",
    "\n",
    "Determines whether two are independent from comparing an observed contingency table agains an expected contingency table generated based on an assumption of independence. \n",
    "\n",
    "$\\large\\sum_{i,\\ j}\\large(\\frac{(O\\ -\\ E)^2}{E})$<br><br>\n",
    "$O = observed$<br>\n",
    "$E = expected = \\large\\frac{row\\_total \\ \\bullet \\ column\\_total}{ total\\_surveyed}$ <br><br>\n",
    "$k = number\\_of\\_bins$<br>\n",
    "$df = (number\\_of\\_columns - 1)(number\\_of\\_rows - 1)$<br>\n",
    "\n",
    "*note: the expected value for each bin must be at least 5*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chi^2 p-value = 0.0113\n",
      "The chi^2 p-value = 0.0113 (stats.chi2_contingency method)\n"
     ]
    }
   ],
   "source": [
    "# Illowsky - Example 11.6\n",
    "data = np.array([[111, 96, 48],\n",
    "                 [96, 133, 61],\n",
    "                 [91, 150, 53]])\n",
    "\n",
    "n_terms = data.sum()\n",
    "n_rows = len(data[:, 0])\n",
    "n_cols = len(data[0, :])\n",
    "dof = (n_rows - 1) * (n_cols - 1)\n",
    "\n",
    "expected = np.array([[(data[:, j].sum() * data[i, :].sum()) / n_terms \n",
    "                      for j in range(n_cols)] for i in range(n_rows)])\n",
    "\n",
    "chi2_score = (((data - expected) ** 2) / expected).sum()\n",
    "p_val = stats.chi2.sf(chi2_score, dof)\n",
    "print('The chi^2 p-value = {0:.4f}'.format(p_val))\n",
    "\n",
    "# scipy stats method chi2_contingency\n",
    "chi2_score, p_val, dof, expected = stats.chi2_contingency(data)\n",
    "print('The chi^2 p-value = {0:.4f} (stats.chi2_contingency method)'.format(p_val))\n",
    "\n",
    "# make sure all expected data values are >= 5\n",
    "if np.any(expected < 5):\n",
    "    raise UserWarning('''An expected data value is < 5.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homogeneity<a class=\"anchor\" id=\"chi_homo\"></a> \n",
    "\n",
    "This is the test for independence used to determine the probability that two populations have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74.09090909 77.27272727 62.27272727 36.36363636]\n",
      " [88.90909091 92.72727273 74.72727273 43.63636364]]\n",
      "10.128696811826693\n",
      "0.017503254828611012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[72, 84, 49, 45],\n",
    "                 [91, 86, 88, 35]])\n",
    "\n",
    "n_terms = data.sum()\n",
    "n_rows = 2  # Should always be two here\n",
    "n_cols = len(data[0, :])\n",
    "dof = n_cols - 1\n",
    "\n",
    "expected = np.array([[(data[:,i].sum() * data[j,:].sum()) / n_terms \n",
    "                      for i in range(n_cols)] for j in range(n_rows)])\n",
    "\n",
    "chi_stat = (((data - expected) ** 2) / expected).sum()\n",
    "\n",
    "p_val = stats.chi2.sf(chi_stat, dof)\n",
    "\n",
    "print(expected)\n",
    "print(chi_stat)\n",
    "print(p_val)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test of a single variance<a class=\"anchor\" id=\"chi_var\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.671296296296296\n",
      "4.213272184766762e-05\n"
     ]
    }
   ],
   "source": [
    "n = 25\n",
    "s = 3.5\n",
    "h = 7.2\n",
    "\n",
    "dof = n - 1\n",
    "\n",
    "chi_stat = ((n - 1) * s ** 2) / h ** 2\n",
    "\n",
    "print(chi_stat)\n",
    "\n",
    "p_val = stats.chi2.cdf(chi_stat, dof)  # left tailed\n",
    "\n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.57889660493827\n",
      "6.1840735576337476e-09\n"
     ]
    }
   ],
   "source": [
    "# increasing n increase test statistic, but decreases p-val for both left and right handed tests,\n",
    "# guessing this is related to the change in distribution with dof?\n",
    "\n",
    "n = 50\n",
    "s = 3.5\n",
    "h = 7.2\n",
    "\n",
    "dof = n - 1\n",
    "\n",
    "chi_stat = ((n - 1) * s ** 2) / h ** 2\n",
    "\n",
    "print(chi_stat)\n",
    "\n",
    "p_val = stats.chi2.cdf(chi_stat, dof)  # left tailed\n",
    "\n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.56408163265307\n",
      "1.623621440614767e-11\n"
     ]
    }
   ],
   "source": [
    "n = 25\n",
    "s = 7.2\n",
    "h = 3.5\n",
    "\n",
    "dof = n - 1\n",
    "\n",
    "chi_stat = ((n - 1) * s ** 2) / h ** 2\n",
    "\n",
    "print(chi_stat)\n",
    "\n",
    "p_val = stats.chi2.sf(chi_stat, dof)  # right tailed\n",
    "\n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207.36\n",
      "2.2435449579324275e-21\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "s = 7.2\n",
    "h = 3.5\n",
    "\n",
    "dof = n - 1\n",
    "\n",
    "chi_stat = ((n - 1) * s ** 2) / h ** 2\n",
    "\n",
    "print(chi_stat)\n",
    "\n",
    "p_val = stats.chi2.sf(chi_stat, dof)  # right tailed\n",
    "\n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for correlation coefficient significance\n",
    "Tests null hypothesis that the population correlation coefficient is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = 0.6631, r^2 = 0.4397, p_val = 0.0262\n"
     ]
    }
   ],
   "source": [
    "x = [ 65,  67,  71,  71,  66,  75,  67,  70,  71,  69,  69]\n",
    "y = [175, 133, 185, 163, 126, 198, 153, 163, 159, 151, 159]\n",
    "\n",
    "r, p_val = stats.pearsonr(x, y)\n",
    "print('r = {0:.4f}, r^2 = {1:.4f}, p_val = {2:.4f}'.format(r, r ** 2, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources<a class=\"anchor\" id=\"sources\"></a>\n",
    "\n",
    "Illowsky, Barbara; Dean, Susan. Introductory Statistics. OpenStax College. Kindle Edition\n",
    "https://openstax.org/details/introductory-statistics\n",
    "\n",
    "SciPy 1.0.0 Release Notes: https://docs.scipy.org/doc/scipy/reference/index.html\n",
    "\n",
    "Jacob Cohen. The Earth Is Round (p < .05) https://www.ics.uci.edu/~sternh/courses/210/cohen94_pval.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
